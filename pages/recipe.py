from langchain_core.messages import HumanMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from IPython.display import Image, display
from google import genai
from google.genai import types
from PIL import Image as Image1
from io import BytesIO
import os
import base64
import streamlit as st
from utils.sidebar import render_sidebar
from utils.speech import speech_to_text

key = st.secrets['Gemini']['API_KEY']

llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    google_api_key=key,
)

client = genai.Client(
        api_key=key,
)

st.title('Recipe é£Ÿè­œæ¨è–¦')

# å‡è¨­ä½¿ç”¨è€…è³‡è¨Š
#user_profile = {
#    "age": 30,
#    #"conditions": ["é«˜è¡€å£“", "ç³–å°¿ç—…"],
#    "conditions": ["éèƒ–"],
#    "dietary_preferences": ["éæ•åŸ:èŠ±ç”Ÿ"],
#}

#user_input = "é›è›‹ã€ç‰›å¥¶ã€éºµåŒ…ã€é¦™è•‰ã€è˜‹æœã€å¥¶æ²¹ï¼Œè«‹çµ¦ä¸­å¼æ—©é¤é£Ÿè­œã€‚"
use_speech = st.toggle(r"$\textsf{\Large ä½¿ç”¨èªéŸ³è¼¸å…¥}$", value=True)
st.text('è«‹è¼¸å…¥é£Ÿå“ææ–™ã€å¹´ç´€ã€èº«é«”ç‹€æ³ã€éæ•åŸå’Œé£²é£Ÿåå¥½ã€‚')
if use_speech:
    st.text('(ä¹Ÿå¯ä»¥æè¿°ä½ è¦çš„æ¨£å¼ (ä¸­å¼è¥¿å¼ã€æ—©é¤æ™šé¤ç­‰ç­‰) )')
    user_input = speech_to_text(1)
else:
    user_input = st.text_input(r'$\textsf{(ä¹Ÿå¯ä»¥æè¿°ä½ è¦çš„æ¨£å¼ (ä¸­å¼è¥¿å¼ã€æ—©é¤æ™šé¤ç­‰ç­‰) )}$', key=1)

st.text('')
st.text('')

#image_urls = [
#   "https://nutritionsource.hsph.harvard.edu/wp-content/uploads/2024/11/AdobeStock_118383793.jpeg",
#   "https://orchardfruit.com/cdn/shop/files/Red-Onion-1-lb.-The-Orchard-Fruit-72141081.jpg?crop=center&height=1200&v=1722937869&width=1200",
#   "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRids7Po0FF0aWy4bj3sjHO3KfzUsaEjCjQ1w&s",
#   "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSzlXU9AXfNSFjZmBsOW-JyvP6WEhJL1eOSHA&s",
#   "https://images.albertsons-media.com/is/image/ABS/136200003-ECOM?$ng-ecom-pdp-desktop$&defaultImage=Not_Available",
#]

images = []
uploaded_photos = st.file_uploader(r"$\textsf{ä¹Ÿå¯ä»¥è¼¸å…¥ææ–™åœ–ç‰‡\\(æœ€å¤š4å¼µï¼Œå¯ä»¥æ‹ç…§æ­é…ä¸Šå‚³ã€‚å–®å¼µç…§ç‰‡å¯ä»¥å¤šç¨®é£Ÿæ)}$", \
                type=["png", "jpeg", "jpg", "webp", "avif"], accept_multiple_files=True)
if uploaded_photos:
    for i in range(len(uploaded_photos)):
        uploaded_photos[i] = uploaded_photos[i].read()
        images.append(uploaded_photos[i])

camera_photo = st.camera_input(r"$\textsf{\Large æ‹ææ–™ç…§ç‰‡}$")
if camera_photo:
    bytes_data = camera_photo.getvalue()
    images.append(bytes_data)

# Gemini prompt
prompt = f"""
ä½ æ˜¯é£Ÿè­œæ¨è–¦å°å¹«æ‰‹ï¼Œä½¿ç”¨è€…æœƒæè¿°å¹´ç´€ã€èº«é«”ç‹€æ³ã€éæ•åŸå’Œé£²é£Ÿåå¥½ã€‚
ä½¿ç”¨è€…æœ‰æ™‚ä¹Ÿæœƒæ­é…åœ–ç‰‡ã€‚
ä½¿ç”¨è€…çš„é£Ÿå“ææ–™å’Œå»ºè­°ç­‰ç­‰æ˜¯ï¼šã€Œ{user_input}ã€ã€‚

è«‹å¹«æˆ‘ï¼š
1. æ ¹æ“šä½¿ç”¨è€…çš„å¹´é½¡ã€å¥åº·ç‹€æ³å’Œæœ‰çš„ææ–™ç­‰ï¼Œæ¨è–¦ä¸€å€‹é©åˆçš„é£Ÿè­œ
2. å›ç­”è«‹ç”¨**ä½¿ç”¨è€…çš„èªè¨€**
3. éƒ½ä¸ç”¨å¤ªå¤šå­—ï¼Œç°¡æ½”æ˜ç­
"""

if st.button('ç”Ÿæˆé£Ÿè­œ'):
    with st.spinner('è«‹ç¨ç­‰...'):
        user_messages = [{"type": "text", "text": prompt}]
        if images:
            if len(images) > 1:
                for image in images:
                    encoded_image = base64.b64encode(image).decode("utf-8")
                    user_messages.append({
                        "type": "image_url",
                        "image_url": {"url": f"data:image/jpeg;base64,{encoded_image}"}
                    })
            else:
                # å¦‚æœåªæœ‰ä¸€å¼µåœ–ç‰‡ï¼Œç›´æ¥ä½¿ç”¨
                encoded_image = base64.b64encode(images[0]).decode("utf-8")
                img_messages = [{
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{encoded_image}"}
                }]
                img_messages.append({"type": "text", "text": "è«‹æè¿°ç…§ç‰‡è£¡æœ‰ä»€éº¼é£Ÿç‰©ã€‚"})
                img_result = llm.invoke([HumanMessage(content=img_messages)])
                user_messages.append({"type": "text", "text": img_result.content})
            
        human_messages = HumanMessage(content=user_messages)
        result = llm.invoke([human_messages])
        st.text_area('AI', result.content, height=400)

        # ç”Ÿæˆåœ–ç‰‡
        contents = (result.content + "\nè«‹æ ¹æ“šä¸Šè¿°é£Ÿè­œç”Ÿæˆä¸€å¼µå®Œæˆçš„æ–™ç†åœ–ç‰‡ï¼Œé€¼çœŸã€ç„¡æ–‡å­—ã€‚").strip()

        response = client.models.generate_content(
            model="gemini-2.0-flash-preview-image-generation",
            contents=contents,
            config=types.GenerateContentConfig(
            response_modalities=['TEXT', 'IMAGE']
            )
        )
        # é¡¯ç¤ºè¼¸å‡º
        #print("ğŸ§  Gemini å»ºè­°ï¼š\n")
        #print(result.content)
        # é¡¯ç¤ºåœ–ç‰‡
        for part in response.candidates[0].content.parts:
            if part.inline_data is not None:
                image = Image1.open(BytesIO((part.inline_data.data)))
                #display(image)
                st.image(image, caption="ç”Ÿæˆçš„æ–™ç†åœ–ç‰‡", use_container_width=True)

render_sidebar()