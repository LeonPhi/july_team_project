from langchain_core.messages import HumanMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from IPython.display import Image, display
from google import genai
from google.genai import types
from PIL import Image as Image1
from io import BytesIO
import os
import base64
import streamlit as st

key = st.secrets['Gemini']['API_KEY']

llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    google_api_key=key,
)

client = genai.Client(
        api_key=key,
)

st.title('Recipe é£Ÿè­œæ¨è–¦')

# å‡è¨­ä½¿ç”¨è€…è³‡è¨Š
user_profile = {
    "age": 30,
    #"conditions": ["é«˜è¡€å£“", "ç³–å°¿ç—…"],
    "conditions": ["éèƒ–"],
    "dietary_preferences": ["éæ•åŸ:èŠ±ç”Ÿ"],
}

#user_input = "é›è›‹ã€ç‰›å¥¶ã€éºµåŒ…ã€é¦™è•‰ã€è˜‹æœã€å¥¶æ²¹ï¼Œè«‹çµ¦ä¸­å¼æ—©é¤é£Ÿè­œã€‚"
user_input = st.text_input('''è«‹è¼¸å…¥é£Ÿå“ææ–™ã€å¹´ç´€ã€èº«é«”ç‹€æ³ã€éæ•åŸå’Œé£²é£Ÿåå¥½ã€‚
                           (ä¹Ÿå¯ä»¥æè¿°ä½ è¦çš„æ¨£å¼ (ä¸­å¼è¥¿å¼ã€æ—©é¤æ™šé¤ç­‰ç­‰) )''', key=1)
#image_urls = [
#   "https://nutritionsource.hsph.harvard.edu/wp-content/uploads/2024/11/AdobeStock_118383793.jpeg",
#   "https://orchardfruit.com/cdn/shop/files/Red-Onion-1-lb.-The-Orchard-Fruit-72141081.jpg?crop=center&height=1200&v=1722937869&width=1200",
#   "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRids7Po0FF0aWy4bj3sjHO3KfzUsaEjCjQ1w&s",
#   "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSzlXU9AXfNSFjZmBsOW-JyvP6WEhJL1eOSHA&s",
#   "https://images.albertsons-media.com/is/image/ABS/136200003-ECOM?$ng-ecom-pdp-desktop$&defaultImage=Not_Available",
#]
images = []
uploaded_file = st.file_uploader("ä¹Ÿå¯ä»¥è¼¸å…¥ææ–™åœ–ç‰‡ (æœ€å¤š4å¼µ)", type=["png", "jpeg", "jpg", "webp", "avif"], accept_multiple_files=True)
if uploaded_file:
    for i in range(len(uploaded_file)):
        uploaded_file[i] = uploaded_file[i].read()
        images.append(uploaded_file[i])

# Gemini prompt
prompt = f"""
ä½ æ˜¯é£Ÿè­œæ¨è–¦å°å¹«æ‰‹ï¼Œæœƒæè¿°å¹´ç´€ã€èº«é«”ç‹€æ³ã€éæ•åŸå’Œé£²é£Ÿåå¥½ã€‚

ä½¿ç”¨è€…çš„é£Ÿå“ææ–™å’Œå»ºè­°ç­‰ç­‰æ˜¯ï¼šã€Œ{user_input}ã€ã€‚

è«‹å¹«æˆ‘ï¼š
1. æ ¹æ“šä½¿ç”¨è€…çš„å¹´é½¡ã€å¥åº·ç‹€æ³å’Œæœ‰çš„ææ–™ç­‰ï¼Œæ¨è–¦ä¸€å€‹é©åˆçš„é£Ÿè­œ
2. å›ç­”è«‹ç”¨ç¹é«”ä¸­æ–‡
3. éƒ½ä¸ç”¨å¤ªå¤šå­—ï¼Œç°¡æ½”æ˜ç­
"""

user_messages = [{"type": "text", "text": prompt}]
if images:
    if len(images) > 1:
       for image in images:
           encoded_image = base64.b64encode(image).decode("utf-8")
           user_messages.append({
               "type": "image_url",
               "image_url": {"url": f"data:image/jpeg;base64,{encoded_image}"}
           })
    else:
       # å¦‚æœåªæœ‰ä¸€å¼µåœ–ç‰‡ï¼Œç›´æ¥ä½¿ç”¨
        img_messages = [{"type": "image_url", "image_url": {"url": images[0]}}]
        img_messages.append({"type": "text", "text": "è«‹æè¿°ç…§ç‰‡è£¡æœ‰ä»€éº¼é£Ÿç‰©ã€‚"})
        img_result = llm.invoke([HumanMessage(content=img_messages)])
        user_messages.append({"type": "text", "text": img_result.content})
human_messages = HumanMessage(content=user_messages)

if st.button('ç”Ÿæˆé£Ÿè­œ'):
    result = llm.invoke([human_messages])
    st.text_area('AI', result.content, height=400)

    # ç”Ÿæˆåœ–ç‰‡
    contents = (result.content + "\nè«‹æ ¹æ“šä¸Šè¿°é£Ÿè­œç”Ÿæˆä¸€å¼µå®Œæˆçš„æ–™ç†åœ–ç‰‡ï¼Œé€¼çœŸã€ç„¡æ–‡å­—ã€‚").strip()

    response = client.models.generate_content(
        model="gemini-2.0-flash-preview-image-generation",
        contents=contents,
        config=types.GenerateContentConfig(
        response_modalities=['TEXT', 'IMAGE']
        )
    )
    # é¡¯ç¤ºè¼¸å‡º
    #print("ğŸ§  Gemini å»ºè­°ï¼š\n")
    #print(result.content)
    # é¡¯ç¤ºåœ–ç‰‡
    for part in response.candidates[0].content.parts:
        if part.inline_data is not None:
            image = Image1.open(BytesIO((part.inline_data.data)))
            #display(image)
            st.image(image, caption="ç”Ÿæˆçš„æ–™ç†åœ–ç‰‡", use_container_width=True)
